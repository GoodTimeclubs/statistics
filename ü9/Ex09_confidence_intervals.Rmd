---
title: "Exercise Sheet 9: Confidence Intervals with Real R Datasets"
subtitle: "Point estimation, variability, and confidence intervals (mean, variance, proportion, regression)"
author: 
date: 
output:
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE
)
set.seed(42)
```

# Quick reference: common CI building blocks

## Quantiles in R

-   Normal critical value: `qnorm(1 - alpha/2)`
-   t critical value: `qt(1 - alpha/2, df)`
-   chi-square quantiles: `qchisq(p, df)`

## Typical CI shapes

-   **Mean, sigma known (z interval):**
    $\bar x \pm z_{1-\alpha/2}\,\sigma/\sqrt{n}$
-   **Mean, sigma unknown (t interval):**
    $\bar x \pm t_{n-1,1-\alpha/2}\,s/\sqrt{n}$
-   **Variance (normal data):**
    $\sigma^2 \in \left[\frac{(n-1)s^2}{\chi^2_{n-1,1-\alpha/2}},\frac{(n-1)s^2}{\chi^2_{n-1,\alpha/2}}\right]$
-   **Proportion (normal approx):**
    $\hat p \pm z_{1-\alpha/2}\sqrt{\hat p(1-\hat p)/n}$
-   **Exact binomial interval:** `binom.test(x, n)$conf.int`

------------------------------------------------------------------------

# Exercise 1 — Populations, samples, parameters, statistics

In this exercise we use `mtcars$mpg`.

> **Idea:** Treat the full dataset as the “population” for this
> exercise.

```{r}
data(mtcars)
mpg_pop <- mtcars$mpg
mu_pop  <- mean(mpg_pop)  # "population mean" for this exercise
sigma_pop <- sd(mpg_pop)  # "population sd" for this exercise
c(mu_pop = mu_pop, sigma_pop = sigma_pop, N = length(mpg_pop))
```

**Tasks**

1.  In 1–2 sentences each, define (in your own words): - population,
    sample, parameter, statistic.

-   **Population:** The population is the entire set of units or
    observations we are interested in studying; here, it would be the
    mpg values of all cars of interest (for this exercise, all cars in
    `mtcars`).

-   **Sample:** A sample is a subset of the population that is actually
    observed and used for analysis; for example, a selection of cars
    whose mpg values are measured.

-   **Parameter:** A parameter is a numerical value that describes a
    characteristic of the population, such as the true mean or standard
    deviation of mpg across all cars in the population.

-   **Statistic:** A statistic is a numerical value computed from a
    sample, like the sample mean or sample standard deviation of mpg,
    used to estimate the corresponding population parameter.

2.  Identify in this context: - population = ? - parameter $\mu$ = ? - a
    sample of size $n=10$ = ? - an estimator for $\mu$ = ? - an estimate
    = ?

    -   **Population:** All mpg values of the cars in the `mtcars`
        dataset (treated here as the full population).

    -   **Parameter ( \\mu ):** The true mean mpg of that population,
        i.e. the mean of all `mtcars$mpg` values.

    -   **A sample of size ( n = 10 ):** Any set of 10 mpg values
        randomly chosen from `mtcars$mpg`.

    -   **An estimator for ( \\mu ):** The sample mean ( \\bar{x} ) of
        the 10 selected mpg values.

    -   **An estimate:** The numerical value of ( \\bar{x} ) computed
        from one конкретten (specific) sample of 10 mpg values.

3.  Draw one random sample of size $n=10$ (with replacement) and compute
    the sample mean.

```{r}
# TODO: draw a sample of size 10 and compute its mean
sam <- sample(mpg_pop,10,T)
mean(sam)

```

4.  Explain briefly: why will your answer in (3) change if you re-run
    the code with a different random seed?

------------------------------------------------------------------------

# Exercise 2 — CI for a mean (t-interval)

We want a **95% CI for the mean mpg** of the `mtcars` cars (treating
them as a sample from a broader population).

**Tasks**

1\. Compute $\bar x$, $s$, $n$.

2\. Compute the 95% t-interval for $\mu$ *by hand* using `qt()`.

3\. Check your result with `t.test()`.

```{r}
x_bar <- mu_pop
s <- sigma_pop
n <- length(mpg_pop)

alpha <- 0.05
t <- qt( 1-alpha/2,df = n-1)
SE <- s/sqrt(n)

CI <- c(
  lower <- x_bar - t * SE,
  upper <- x_bar + t * SE
  
)

c(x_bar = x_bar, s = s, n = n, t = t, CI)
```

```{r}
# Check with built-in t.test
ttest1 <- t.test(mtcars$mpg, conf.level = 0.95)
ttest1$conf.int
```

**Questions (write short answers):** - Why do we use a **t** critical
value here instead of a **z** critical value? - Interpret the 95% CI
correctly in frequentist terms (repeated sampling interpretation).

------------------------------------------------------------------------

# Exercise 3 — How CI width changes (confidence level and sample size)

## Part A: Change confidence level (90%, 95%, 99%)

Compute CIs at three confidence levels and compare widths.S

```{r}
ci90 <- t.test(mtcars$mpg, conf.level = 0.90)
ci95 <- t.test(mtcars$mpg, conf.level = 0.95)
ci99 <- t.test(mtcars$mpg, conf.level = 0.99)
w90 <- diff(ci90$conf.int)
w95 <- diff(ci95$conf.int)
w99 <- diff(ci99$conf.int)

list(width90 = w90, width95 = w95, width99 = w99)

```

**Tasks**

1\. Compute the **length** of each interval.

2\. Explain: why does higher confidence produce a wider interval?

Higher confidence means we want to be more sure the true mean is inside
the interval, so we make the interval wider.

```{r}
# TODO: compute interval lengths
w90 <- diff(ci90$conf.int)
w95 <- diff(ci95$conf.int)
w99 <- diff(ci99$conf.int)

list(width90 = w90, width95 = w95, width99 = w99)
```

## Part B: Change sample size (subsampling)

Randomly select half the cars (without replacement) and compute the 95%
CI again.

```{r}
h_cars <- sample(mpg_pop, n/2, F)
diff(t.test(h_cars, conf.level=0.95)$conf.int)

```

**Questions** - Which CI is wider? Why? - What role does the factor
$1/\sqrt{n}$ play?

-   **Which CI is wider?**\
    The CI with the **smaller sample** (half the cars) is wider.

-   **Why?**\
    With fewer data points, we are less sure about the mean.

-   **Role of (1/\\sqrt{n}):**\
    When (n) gets smaller, (1/ \\sqrt{n}) gets bigger, so the interval
    becomes wider.

------------------------------------------------------------------------

# Exercise 4 — CI for a variance (chi-square interval)

Assume (for this exercise) that mpg is approximately normal.

**Tasks**

1\. Compute the sample variance $s^2$.

2\. Build a 95% CI for $\sigma^2$ using the chi-square quantiles.

3\. Optionally convert it to a CI for $\sigma$ by taking square roots.

```{r}
s2 <- var(mpg_pop)
alpha <- 0.05

CI <- c(
  lower <- ((n-1)*s2)/qchisq(1-alpha/2,n-1),
  upper <- ((n-1)*s2)/qchisq(alpha/2,n-1)
)

CI
```

```{r}
# Optional: CI for sigma
CI_sig <- sqrt(CI)
CI_sig
```

**Questions** - Why do chi-square quantiles appear here? - What
assumption is crucial for this variance CI to be exact?

-   **Why chi-square quantiles?**\

    Because for normal data the scaled sample variance
    (n−1)s2/σ2(n-1)s^2/^\sigma2(n−1)s2/σ2 follows a chi-square
    distribution.

-   **Crucial assumption:**\

    The data are **normally distributed**; without normality, this
    variance CI is no longer exact.

------------------------------------------------------------------------

# Exercise 5 — CI for a proportion

`Titanic` is a contingency table. We'll compute the proportion of
passengers who survived.

```{r}
data(Titanic)
Titanic
```

## Part A: Overall survival proportion

Let: - $n$ = total passengers, - $x$ = number of survivors, -
$\hat p = x/n$.

```{r}
n <- sum(Titanic)
x <- sum(Titanic[,,, "Yes"])
p_hat <- x/n
p_hat

```

### Normal-approximate 95% CI

```{r}
prop.test(x, n, conf.level = 0.95, correct = FALSE)$conf.int
```

### Comparision: Exact (Clopper–Pearson) CI

```{r}
ci_exact <- binom.test(x, n, conf.level = 0.95)$conf.int
ci_exact
```

**Questions** - Compare the widths: which interval is wider, and why is
that expected? - Check the rule of thumb: are $n\hat p$ and
$n(1-\hat p)$ at least 10?

**Compare the widths:**

-   The **exact (Clopper–Pearson) CI** is **slightly wider** than the
    normal-approximation CI.

**Why is that expected?**

-   The exact method guarantees the stated coverage for all (p), so it
    is more conservative, while the normal approximation relies on an
    approximation that can be a bit too optimistic.

**Rule of thumb check:**

-   (n\\hat p \\approx 2225 \\times 0.323 \\approx 719 \\ge 10)

-   (n(1-\\hat p) \\approx 2225 \\times 0.677 \\approx 1506 \\ge 10)

Both conditions are easily satisfied, so the normal approximation is
appropriate here.

## Part B: A smaller subgroup (children)

Compute the survival proportion among children only (this subgroup is
smaller).

```{r}
n_child <- sum(Titanic[,,"Child",])
x_child <- sum(Titanic[,,"Child", "Yes"])
p_hat_child <- x_child/n_child

list(adult = p_hat, child = p_hat_child)
```

**Tasks**

1\. Compute normal-approx CI and exact CI for children.

2\. Comment: which method seems more trustworthy here and why?

```{r}
prob.test()
```

------------------------------------------------------------------------

# Exercise 6 — CI for a mean with missing data

The dataset `airquality` has missing values (NA), especially in `Ozone`.

```{r}
data(airquality)
str(airquality)
summary(airquality$Ozone)
```

## Part A: 95% CI for mean Ozone (ignoring missing values)

**Tasks**

1\. Remove NAs from `Ozone`.

2\. Compute $\bar x$, $s$, $n$.

3\. Compute a 95% t-interval for the mean Ozone level.

```{r}

```

## Part B: Compare months (June vs August)

**Tasks**

1\. Make separate vectors of Ozone for Month 6 and Month 8 (remove NAs).

2\. Compute a 95% CI for each mean.

3\. Compare widths and explain differences (think: sample size and
variability).

```{r}

```

**Conceptual question** - Does “non-overlapping 95% CIs” automatically
imply a significant difference at 5%? (Discuss briefly.)

------------------------------------------------------------------------
